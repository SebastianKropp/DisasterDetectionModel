{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Disaster Detection Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.23.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (1.2.2)\n",
      "Requirement already satisfied: torch in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2023.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (5.12.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (9.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (4.39.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 3)) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.12.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (3.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (1.11.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from torch->-r requirements.txt (line 5)) (4.5.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->-r requirements.txt (line 3)) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 5)) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\elmig\\miniconda3\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 5)) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip3 install -r requirements.txt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import math\n",
    "from IPython import display\n",
    "import requests\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "###              EXAMPLE USE:                ###\n",
    "## tweet_text = \"This is a test tweet!\"\n",
    "## sentiment = sentiment_detection(tweet_text)\n",
    "## sarcasm = sarcasm_detection(tweet_text) \n",
    "API_TOKEN = \"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\"\n",
    "\n",
    "def query(API_URL, headers, payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def sentiment_detection(tweet_text):\n",
    "    # Define the first API endpoint and function\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "    # Use the first function to query the sentiment of some text\n",
    "    output_sentiment = query(API_URL, headers, {\n",
    "        \"inputs\": tweet_text,\n",
    "    })\n",
    "\n",
    "    return output_sentiment\n",
    "\n",
    "\n",
    "def sarcasm_detection(tweet_text):\n",
    "    # Define the second API endpoint and function\n",
    "    API_URL = \"https://api-inference.huggingface.co/models/helinivan/english-sarcasm-detector\"\n",
    "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "        \n",
    "    output_sarcasm = query(API_URL, headers, {\n",
    "        \"inputs\": tweet_text,\n",
    "    })\n",
    "\n",
    "    return output_sarcasm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'neutral', 'score': 0.8819799423217773}, {'label': 'positive', 'score': 0.10076777637004852}, {'label': 'negative', 'score': 0.01725233532488346}]]\n",
      "{'error': 'Model helinivan/english-sarcasm-detector is currently loading', 'estimated_time': 20.0}\n"
     ]
    }
   ],
   "source": [
    "#TESTING STUFF\n",
    "print(sentiment_detection(\"I just loveeee stinky smelly stuff\"))\n",
    "print(sarcasm_detection(\"I just loveeee stinky smelly stuff\"))\n",
    "test_1 = sentiment_detection(\"I just loveeee stinky smelly stuff\")\n",
    "test_2 = sarcasm_detection(\"I just loveeee stinky smelly stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'negative', 'score': 0.6726911664009094}, {'label': 'neutral', 'score': 0.18366330862045288}, {'label': 'positive', 'score': 0.14364556968212128}]]\n",
      "0.6726911664009094\n",
      "0.18366330862045288\n",
      "0.14364556968212128\n"
     ]
    }
   ],
   "source": [
    "print(test_1)\n",
    "negative_score = test_1[0][0]['score']\n",
    "neutral_score = test_1[0][1]['score']\n",
    "positive_score = test_1[0][2]['score']\n",
    "\n",
    "\n",
    "print(negative_score)\n",
    "print(neutral_score)\n",
    "print(positive_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'LABEL_0', 'score': 0.8405861854553223}, {'label': 'LABEL_1', 'score': 0.15941382944583893}]]\n",
      "0.8405861854553223\n",
      "0.15941382944583893\n"
     ]
    }
   ],
   "source": [
    "print(test_2)\n",
    "sarcastic = test_2[0][0]['score']\n",
    "not_sarcastic = test_2[0][1]['score']\n",
    "\n",
    "\n",
    "print(sarcastic)\n",
    "print(not_sarcastic)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the api calls to the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time # To add a delay between API calls\n",
    "\n",
    "def process_tweets_1(input_file, output_file):\n",
    "    # Open the input CSV file for reading and the output CSV file for writing\n",
    "    with open(input_file, 'r', newline='') as file_in, open(output_file, 'w', newline='') as file_out:\n",
    "        reader = csv.DictReader(file_in)\n",
    "\n",
    "        # Define the fieldnames for the output CSV file\n",
    "        fieldnames = reader.fieldnames + ['negative', 'neutral', 'positive', 'sarcastic', 'not_sarcastic']\n",
    "        \n",
    "        writer = csv.DictWriter(file_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Read and process each row in the input CSV file\n",
    "        for row in reader:\n",
    "            tweet_text = row['text']  # Assuming the tweet text is in the 'text' column\n",
    "\n",
    "            # Call the sentiment detection and sarcasm detection functions\n",
    "            sentiment_result = sentiment_detection(tweet_text)\n",
    "            sarcasm_result = sarcasm_detection(tweet_text)\n",
    "\n",
    "\n",
    "            # Add the sentiment and sarcasm probabilities to the row\n",
    "            row['negative'] = sentiment_result[0][0]['score']\n",
    "            row['neutral'] = sentiment_result[0][1]['score']\n",
    "            row['positive'] = sentiment_result[0][2]['score']\n",
    "            row['sarcastic'] = sarcasm_result[0][0]['score']\n",
    "            row['not_sarcastic'] = sarcasm_result[0][1]['score']\n",
    "\n",
    "            # Write the updated row to the output CSV file\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            # Delay for one minute before making the next API call\n",
    "            time.sleep(60)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "MAX_RETRY_COUNT = 3\n",
    "RATE_LIMIT_ERROR_MESSAGE = 'Rate limit reached. You reached free usage limit (reset hourly). Please subscribe to a plan at https://huggingface.co/pricing to use the API at this rate'\n",
    "\n",
    "def process_tweets(input_file, output_file, log_file):\n",
    "    # Open the input CSV file for reading, the output CSV file for writing, and the log CSV file for writing unsuccessful runs\n",
    "    with open(input_file, 'r', newline='') as file_in, open(output_file, 'w', newline='') as file_out, open(log_file, 'w', newline='') as file_log:\n",
    "        reader = csv.DictReader(file_in)\n",
    "\n",
    "        # Define the fieldnames for the output CSV file\n",
    "        fieldnames = reader.fieldnames + ['negative', 'neutral', 'positive', 'sarcastic', 'not_sarcastic']\n",
    "        \n",
    "        writer = csv.DictWriter(file_out, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Define the fieldnames for the log CSV file\n",
    "        log_fieldnames = reader.fieldnames\n",
    "        log_writer = csv.DictWriter(file_log, fieldnames=log_fieldnames)\n",
    "        log_writer.writeheader()\n",
    "\n",
    "        # Read and process each row in the input CSV file\n",
    "        for row in reader:\n",
    "            tweet_text = row['text']  # Assuming the tweet text is in the 'text' column\n",
    "            retry_count = 0\n",
    "\n",
    "            while retry_count < MAX_RETRY_COUNT:\n",
    "                # Call the sentiment detection and sarcasm detection functions\n",
    "                sentiment_result = sentiment_detection(tweet_text)\n",
    "                sarcasm_result = sarcasm_detection(tweet_text)\n",
    "\n",
    "                if sentiment_result and sarcasm_result:  # Check if results are not empty\n",
    "                    if (isinstance(sentiment_result[0], dict) and 'error' in sentiment_result[0] and sentiment_result[0]['error'] == RATE_LIMIT_ERROR_MESSAGE) or (isinstance(sarcasm_result[0], dict) and 'error' in sarcasm_result[0] and sarcasm_result[0]['error'] == RATE_LIMIT_ERROR_MESSAGE):\n",
    "                        # Log the row if rate limit error is encountered\n",
    "                        log_writer.writerow(row)\n",
    "                    else:\n",
    "                        # Add the sentiment and sarcasm probabilities to the row\n",
    "                        row['negative'] = sentiment_result[0][0]['score']\n",
    "                        row['neutral'] = sentiment_result[0][1]['score']\n",
    "                        row['positive'] = sentiment_result[0][2]['score']\n",
    "                        row['sarcastic'] = sarcasm_result[0][0]['score']\n",
    "                        row['not_sarcastic'] = sarcasm_result[0][1]['score']\n",
    "\n",
    "                        # Write the updated row to the output CSV file\n",
    "                        writer.writerow(row)\n",
    "                    break\n",
    "                else:\n",
    "                    # Log the unsuccessful run\n",
    "                    log_writer.writerow(row)\n",
    "\n",
    "                    retry_count += 1\n",
    "                    time.sleep(60)  # Delay for one minute before making the next retry\n",
    "\n",
    "            if retry_count == MAX_RETRY_COUNT:\n",
    "                # If maximum retry count reached, write the original row to the output CSV file\n",
    "                writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m output_csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpreprocessed_test.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      3\u001b[0m log_csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlog.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m process_tweets(input_csv_file, output_csv_file, log_csv_file)\n",
      "Cell \u001b[1;32mIn[52], line 34\u001b[0m, in \u001b[0;36mprocess_tweets\u001b[1;34m(input_file, output_file, log_file)\u001b[0m\n\u001b[0;32m     31\u001b[0m sarcasm_result \u001b[39m=\u001b[39m sarcasm_detection(tweet_text)\n\u001b[0;32m     33\u001b[0m \u001b[39mif\u001b[39;00m sentiment_result \u001b[39mand\u001b[39;00m sarcasm_result:  \u001b[39m# Check if results are not empty\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(sentiment_result[\u001b[39m0\u001b[39;49m], \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m sentiment_result[\u001b[39m0\u001b[39m] \u001b[39mand\u001b[39;00m sentiment_result[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m RATE_LIMIT_ERROR_MESSAGE) \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(sarcasm_result[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m sarcasm_result[\u001b[39m0\u001b[39m] \u001b[39mand\u001b[39;00m sarcasm_result[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m RATE_LIMIT_ERROR_MESSAGE):\n\u001b[0;32m     35\u001b[0m         \u001b[39m# Log the row if rate limit error is encountered\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         log_writer\u001b[39m.\u001b[39mwriterow(row)\n\u001b[0;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[39m# Add the sentiment and sarcasm probabilities to the row\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "input_csv_file = 'test.csv'\n",
    "output_csv_file = 'preprocessed_test.csv'\n",
    "log_csv_file = 'log.csv'\n",
    "\n",
    "process_tweets(input_csv_file, output_csv_file, log_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m input_csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      2\u001b[0m output_csv_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpreprocessed_train.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m process_tweets(input_csv_file, output_csv_file)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "input_csv_file = 'train.csv'\n",
    "output_csv_file = 'preprocessed_train.csv'\n",
    "\n",
    "process_tweets(input_csv_file, output_csv_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('preprocessed_train.csv', sep=',', encoding='latin-1')\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1731    0\n",
      "2921    1\n",
      "5415    0\n",
      "7374    0\n",
      "1958    1\n",
      "       ..\n",
      "5815    0\n",
      "3817    0\n",
      "2941    0\n",
      "6775    0\n",
      "6287    1\n",
      "Name: target, Length: 6088, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = train_df[['keyword', 'location', 'sarcastic', 'not_sarcastic', 'negative', 'neutral', 'positive']]\n",
    "target = train_df['target']\n",
    "#print(X_data[\"neutral\"])\n",
    "train_data, val_data, train_target, val_target = train_test_split(data, target, test_size = 0.2)\n",
    "print(train_target)\n",
    "# split the dataset into training and validation sets\n",
    "#train_data, val_data = \n",
    "#print(train_data[:][\"sarcastic\"])\n",
    "#train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "#val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert categorical features in a DataFrame to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def convert_features_to_one_hot(df, feature_name_list):\n",
    "  for feature_name in feature_name_list:\n",
    "    df = pd.get_dummies(df, columns=[feature_name])\n",
    "  \n",
    "  return df\n",
    "#Define the training set/test set from the imported data... x_train, x_val, etc... needs to be predefined\n",
    "\n",
    "data_to_convert = ['train_data', 'val_data']\n",
    "\n",
    "feature_list = ['location', 'keyword']\n",
    "for i,ix in enumerate(data_to_convert):\n",
    "  exec(f'{data_to_convert[i]} = convert_features_to_one_hot({ix}, {feature_list})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2959\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.keys()))\n",
    "input_layers = len(train_data.keys())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model draft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class netmodel(nn.Module):\n",
    "  def __init__(self, input_layer=1, num_hidden=1, node_per_hidden=32, droppout=0., LSTM_layers=0, outputs=2):\n",
    "    super(netmodel, self).__init__()\n",
    "    self.input_layer = input_layer\n",
    "    self.num_hidden = num_hidden \n",
    "    self.node_per_hidden = node_per_hidden\n",
    "    self.droppout = droppout \n",
    "    self.SLTM_layers = LSTM_layers \n",
    "    self.outputs = outputs \n",
    "    self.inputfc = nn.Linear(input_layer, node_per_hidden) \n",
    "    self.hiddenfc = [] \n",
    "    for i in range(num_hidden-1):\n",
    "      self.hiddenfc.append(nn.Linear(node_per_hidden, node_per_hidden))\n",
    "    self.lastfc = nn.Linear(node_per_hidden, outputs)\n",
    "\n",
    "  def forward(self, x, debug=False):\n",
    "    drop = nn.Dropout(p=self.droppout)\n",
    "    #x = x.view(1,1)\n",
    "    x = self.inputfc(x)\n",
    "    x = F.relu(x)\n",
    "    x = drop(x)\n",
    "    for i in range(self.num_hidden-1):\n",
    "      x = self.hiddenfc[i](x)\n",
    "      x = F.relu(x)\n",
    "      x = drop(x)\n",
    "    \n",
    "    x = self.lastfc(x)\n",
    "    x = F.softmax(x, dim=1)\n",
    "    return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "Model = netmodel(input_layer=input_layers, num_hidden=3, droppout=0.3).to(device)\n",
    "\n",
    "#Model.forward(torch.tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6088\n",
      "6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmig\\AppData\\Local\\Temp\\ipykernel_47164\\925260133.py:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tensor_train = torch.tensor(train_data.values.astype(np.float), dtype=torch.float32).to(device)\n",
      "C:\\Users\\elmig\\AppData\\Local\\Temp\\ipykernel_47164\\925260133.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tensor_train_labels = torch.tensor(train_target.values.astype(np.float), dtype=torch.float32).to(device)\n",
      "C:\\Users\\elmig\\AppData\\Local\\Temp\\ipykernel_47164\\925260133.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tensor_val = torch.tensor(val_data.values.astype(np.float), dtype=torch.float32).to(device)\n",
      "C:\\Users\\elmig\\AppData\\Local\\Temp\\ipykernel_47164\\925260133.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tensor_val_labels = torch.tensor(val_target.values.astype(np.float), dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 32\n",
    "print(len(train_data))\n",
    "print(len(train_target))\n",
    "#tensor_train = torch.utils.data.TensorDataset(train_data, train_target)\n",
    "tensor_train = torch.tensor(train_data.values.astype(np.float), dtype=torch.float32).to(device)\n",
    "tensor_train_labels = torch.tensor(train_target.values.astype(np.float), dtype=torch.float32).to(device)\n",
    "tensor_train_set = torch.utils.data.TensorDataset(tensor_train, tensor_train_labels)\n",
    "\n",
    "# Convert validation data to PyTorch tensors and move to device\n",
    "#tensor_val = torch.utils.data.TensorDataset(val_data, val_target)\n",
    "tensor_val = torch.tensor(val_data.values.astype(np.float), dtype=torch.float32).to(device)\n",
    "tensor_val_labels = torch.tensor(val_target.values.astype(np.float), dtype=torch.float32).to(device)\n",
    "tensor_val_set = torch.utils.data.TensorDataset(tensor_val, tensor_val_labels)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(tensor_train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(tensor_val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "lr = 1e-3\n",
    "lambda_l2 = 1e-3\n",
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(Model.parameters(), lr=lr, weight_decay=lambda_l2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(epochs, model):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "      for batch_id, (data, label) in enumerate(train_loader):\n",
    "        #print(batch_idx)\n",
    "\n",
    "\n",
    "        pred = Model.forward(data)\n",
    "        print(type(pred[0][0].item()))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(pred.type(torch.LongTensor), label.type(torch.LongTensor))\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_id % 60 == 0:\n",
    "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_id * len(data), len(train_loader.dataset),\n",
    "            100. * batch_id / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[214], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(\u001b[39m1\u001b[39;49m, Model)\n",
      "Cell \u001b[1;32mIn[213], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(epochs, model)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(pred[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem()))\n\u001b[0;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m loss \u001b[39m=\u001b[39m loss_func(pred\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mLongTensor), label\u001b[39m.\u001b[39;49mtype(torch\u001b[39m.\u001b[39;49mLongTensor))\n\u001b[0;32m     13\u001b[0m \u001b[39m#print(loss)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \"log_softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "train_model(1, Model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
